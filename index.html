<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
<title>Liangcai Su's Personal Homepage</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Liangcai Su (ËãèËâØÊâç)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https:/liangcaisu.github.io/"><img src="picture/photo.jpg" alt="alt text" width="130px" /></a>&nbsp;</td>
<td align="left"><p>
<!-- <br><br /> -->
Liangcai Su (ËãèËâØÊâç)<br />
Computer Science, Ph.D. Student<br />
The University of Hong Kong<br />
Email: liangcaisu@connect.hku.hk<br />
<br />
<!-- <a href="pdf/Aikun_Xu_CV.pdf">[CV]</a> -->
<a href="https://scholar.google.com/citations?user=h11w7y4AAAAJ&hl=zh-CN">[Google Scholar]</a> 
<!-- <a href="https://dblp.org/pid/270/6458.html">[DBLP]</a>  -->
<a href="https://github.com/LiangcaiSu">[GitHub]</a>
<!-- <a href="https://www.linkedin.com/in/kelong-mao-77442a15a/">[Linkedin]</a> -->
</td></tr></table>

<h2>About</h2>
<p> I am a Ph.D. student at The University of Hong Kong, majoring in Computer Science. Also, I am a research intern focusing on deep research agents at Tongyi Lab now. Previously, 
I received my Master's degree in Computer Technology from Tsinghua University in 2024 and obtained my B.Eng degree in Software Engineering from Xidian University in 2021.
I was a research intern supervised by <a href="http://jiemingzhu.github.io/">Jieming Zhu</a> and at Tencent mentored by <a target="_blank" rel="noopener"
  href="https://scholar.google.com/citations?user=sUaBkFkAAAAJ&hl=en&oi=ao">Junwei Pan</a> and <a target="_blank" rel="noopener"
  href="https://wxm17.github.io">Ximei Wang</a>.
</p> 


<p> My research directions are Data Mining and Deep Research Agent. </p>

<h2>News</h2>
<ul>
  <li><strong>[Sep. 2025]</strong> We release our open-source and powerful deep research agent <strong>Tongyi DeepResearch</strong>! Please see  <a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/">the tech blog</a> for details. Our model is available at <a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B">huggingface</a> and 
  <a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B">modelscope</a>.</li>
  <li><strong>[Sep. 2025]</strong> We release our work <em>Scaling Agents via Continual Pre-training!</em></li>
  <li><strong>[Aug. 2025]</strong> Our work <em>ImportSnare</em> was accepted by CCS 2025. üéâ</li>
  <li><strong>[Jan. 2025]</strong> One paper about unlearnable data was accepted by ICLR 2025. <span style='font-size:20;'>&#129321;</span>    See you in Singapore!</li>
  <li><strong>[July. 2024]</strong> Our paper ERASE was accepted by CIKM 2024. Congrast to Ling-Hao Chen! </li>
  <li><strong>[June. 2024]</strong> Our paper (Invisibility Cloak) was accepted by USENIX Security 2024. </li>
  <li><strong>[May. 2024]</strong> Our latest <a href="https://arxiv.org/abs/2405.09592">survey paper</a> on generative techniques for spatial-temporal data mining is now available. </li>
  <!-- <li><strong>[Nov. 2023]</strong> Our paper about Multi-model recommendation was accepted by ICASSP 2024. Congrats to Xiaoteng Shen!</li> -->
  <!-- <li><strong>[Nov. 2023]</strong> Our paper about Multi-task recommendation was accepted by AAAI 2024. <span style='font-size:20;'>&#129321;</span>    See you in Vancouver!</li> -->
  <!-- <li><strong>[Apr. 2023]</strong> Our paper about Candidate matching was accepted by SIGIR 2023.</li> -->
  <!-- <li><strong>[Nov. 2022]</strong> One paper about CTR prediction was accepted by AAAI 2023.</li> -->
  <!-- <li><strong>[Apr. 2022]</strong> I was selected for "Tencent Rhino-Bird Research Elite Program 2022".</li> -->
  <!-- <li><strong>[Apr. 2022]</strong> One paper about Benchmarking for recommender systems  was accepted by SIGIR 2022.</li> -->
  <!-- <li><strong>[Jan. 2022]</strong> One paper about Re-ranking was accepted by WWW 2022.</li> -->
</ul>



<h2>Research Experiences</h2>
<ul>
  <li><strong>Tongyi Lab (Deep Research Team)</strong>, Research Intern. May. 2025 - </li>
  <li><strong>The University of Hong Kong</strong>, Research Assistant. Nov. 2023 - Aug. 2024</li>
  <li><strong>Tencent</strong>, Research Intern. Jun. 2022 - Nov. 2023</li>
  <!-- <li><strong>Huawei Noah's Ark Lab</strong>, Research Intern. Mar. 2021 - Sep. 2021 & Feb. 2022 - May. 2022.</li> -->
</ul>


<h2>Publications</h2>
(* denotes equal contributions)

<ul>
  <li><p>Scaling Agents via Continual Pre-training<br />
    <strong>Liangcai Su*</strong>, Zhen Zhang*, Guangyu Li*, Zhuo Chen*, Chenxi Wang*, and others.<br /> 
    Arxiv 2025. <a href="https://arxiv.org/abs/2509.13310">[Paper]</a><a href="https://github.com/Alibaba-NLP/DeepResearch/">[Github]</a> 
    <a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B">[Huggingface]</a> 
    <a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B">[Modelscope]</a>
    <a href="https://tongyi-agent.github.io/">[Blog]</a>
  </p>
  </li>  

  <li><p>ImportSnare: Directed "Code Manual" Hijacking in Retrieval-Augmented Code Generation<br />
    Kai Ye, <strong>Liangcai Su</strong>, Chenxiong Qian.<br /> 
    CCS 2025. <a href="https://importsnare.github.io/">[Project]</a></p>
  </li>  
  <li><p>How Far Are We from True Unlearnability?<br />
    Kai Ye*, <strong>Liangcai Su*</strong>, Chenxiong Qian.<br />
        ICLR 2025. <a href="https://arxiv.org/abs/2509.08058">[Paper]</a></p>
  </li>  
  <li><p>STEM: Unleashing the Power of Embeddings for Multi-task Recommendation <br />
    <strong>Liangcai Su*</strong>, Junwei Pan*, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, Jie Jiang. <br />AAAI 2024. <a href="https://arxiv.org/abs/2308.13537">[Paper]</a> <a href="https://github.com/LiangcaiSu/STEM">[Code]</a>  </p>
      </li>  
  <li><p>ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance<br />
    Ling-Hao Chen, Yuanshuo Zhang, Taohua Huang, <strong>Liangcai Su</strong>, Zeyi Lin, Xi Xiao, Xiaobo Xia, Tongliang Liu.<br />
    CIKM 2024. <a href="https://arxiv.org/pdf/2312.08852">[Paper]</a><a href="https://eraseai.github.io/ERASE-page">[Project]</a><a href="https://github.com/eraseai/erase">[Code]</a></p>
  </li>  
  <li><p>Invisibility Cloak: Proactive Defense Against Visual Game Cheating<br />
    Chenxin Sun, Kai Ye, <strong>Liangcai Su</strong>, Jiayi Zhang, and Chenxiong Qian.<br />
    USENIX Security 2024. <a href="https://inviscloak.github.io/">[Demo]</a>  </p>
  </li>  
  <li><p>A Survey of Generative Techniques for Spatial-Temporal Data Mining<br />
    Qianru Zhang, Haixin Wang, Cheng Long, <strong>Liangcai Su</strong>, Xingwei He, Jianlong Chang, Tailin Wu, Hongzhi Yin, Siu-Ming Yiu, Qi Tian and Christian S. Jensen.<br />
        Preprint. <a href="https://arxiv.org/abs/2405.09592">[Paper]</a>  </p>
  </li> 
  <li><p>Multi-interest Learning for Multi-modal Paper Recommendation<br />
    Xiaoteng Shen*, <strong>Liangcai Su*</strong>, Xi Xiao, Yi Li<br />
        ICASSP 2024. <a href="https://ieeexplore.ieee.org/abstract/document/10446181">[Paper]</a>  </p>
  </li> 
  <li><p>Beyond Two-Tower Matching: Learning Sparse Retrievable Interaction Models for Recommendation<br />
    <strong>Liangcai Su</strong>, Fan Yan, Jieming Zhu, Xi Xiao, Haoyi Duan, Zhou Zhao, Zhenhua Dong and Ruiming Tang.<br />
        SIGIR 2023. <a href="https://dl.acm.org/doi/abs/10.1145/3539618.3591643">[Paper]</a>  </p>
      </li>  
  <li><p>FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction<br />
    Kelong Mao, Jieming Zhu, <strong>Liangcai Su</strong>, Guohao Cai, Yuru Li, Zhenhua Dong.<br />
    AAAI 2023. <a href="https://arxiv.org/pdf/2304.00902.pdf">[Paper]</a> <a href="https://github.com/reczoo/FuxiCTR/tree/main/model_zoo/FinalMLP">[Code]</a> </p>
  </li>
  <li><p>BARS: Towards Open Benchmarking for Recommender Systems<br />
    Jieming Zhu, Quanyu Dai, <strong>Liangcai Su</strong>, Rong Ma, Jinyang Liu, Guohao Cai, Xi Xiao, Rui Zhang. <br />
    SIGIR 2022. <a href="https://arxiv.org/abs/2205.09626">[Paper]</a> <a href="https://github.com/openbenchmark/BARS">[Code]</a> <a href="https://openbenchmark.github.io/BARS/">[Project]</a> </p> 
  </li>
  <li><p>PEAR: Personalized Re-ranking with Contextualized Transformer for Recommendation <br />
    Yi Li, Jieming Zhu, Weiwen Liu, <strong>Liangcai Su</strong>, Guohao Cai, Qi Zhang, Ruiming Tang, Xi Xiao, Xiuqiang He. <br />
    WWW 2022. <a href="https://dl.acm.org/doi/10.1145/3487553.3524208">[Paper]</a>
  </p></li>
</ul>

<!-- <h2>Preprints</h2> -->


<h2>Awards</h2>
<ul>
  <li>Outstanding Graduates of Beijing(Âåó‰∫¨Â∏Ç‰ºòÁßÄÊØï‰∏öÁîü), 2024. </li>
  <li>Best Report Award, The 15th Nanshan Academic Forum for Doctoral Students in the Guangdong-Hong Kong-Macao Greater Bay Area, 2023. </li>
  <li>ACM SIGIR 2023 Student Travel Award. </li>
  <li>Comprehensive Excellent Second-class Scholarship, Tsinghua University, 2022 & 2023 (Two times).</li>
  <li>National Scholarship(ÂõΩÂÆ∂Â•ñÂ≠¶Èáë), 2019-2020. (Top 1% Student in XDU) </li>
  <li>National Scholarship(ÂõΩÂÆ∂Â•ñÂ≠¶Èáë), 2017-2018. (Top 1% Student in XDU) </li>
</ul>


<div id="footer">
<div id="footer-text">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VGMZSKJ2WQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VGMZSKJ2WQ');
</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?a4e08f102e0496f04fabcc2686260f37";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
</div>
</div>
</div>
</body>
</html>
